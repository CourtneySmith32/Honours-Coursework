{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.tri as Tri\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "import netCDF4\n",
    "from netCDF4 import num2date, date2num, date2index\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from StringIO import StringIO\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractURLsatellite(fileURL, satName):\n",
    "    \"\"\"\n",
    "    Function to extract the URLs for a specific satellite from the IMOS URLs list\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - fileURL : IMOS URLs list as a txt file\n",
    "    - satName : name of the satellite such as JASON-2 JASON-3 \n",
    "    \n",
    "    Ouputs:\n",
    "    ------\n",
    "    \n",
    "    - getFiles : list of URLs for the desired satellite\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    getFiles = []\n",
    "    \n",
    "    with open(fileURL) as f:\n",
    "        for line in f:\n",
    "            if re.search(r\"%s\"%satName, line):\n",
    "                changeURL = re.sub('http://data.aodn.org.au', 'http://thredds.aodn.org.au/thredds/dodsC', line)\n",
    "                getFiles.append(changeURL)\n",
    "                \n",
    "    return getFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jason2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-2')\n",
    "\n",
    "jason3URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-3')\n",
    "\n",
    "saralURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SARAL')\n",
    "\n",
    "sentinel3aURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SENTINEL-3A')\n",
    "\n",
    "cryosat2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'CRYOSAT-2')\n",
    "\n",
    "enviURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ENVISAT')\n",
    "\n",
    "geosatURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GEOSAT')\n",
    "\n",
    "ersURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ERS-2')\n",
    "\n",
    "gfoURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GFO')\n",
    "\n",
    "topURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'TOPEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allURL = []\n",
    "allURL.append(jason2URL)\n",
    "allURL.append(jason3URL)\n",
    "allURL.append(saralURL)\n",
    "allURL.append(sentinel3aURL)\n",
    "allURL.append(cryosat2URL)\n",
    "allURL.append(enviURL)\n",
    "allURL.append(geosatURL)\n",
    "allURL.append(ersURL)\n",
    "allURL.append(gfoURL)\n",
    "allURL.append(topURL)\n",
    "\n",
    "boxLat = [] #latitude\n",
    "boxLon = [] #longitude\n",
    "boxWh = [] #wave height\n",
    "boxT = [] #time\n",
    "boxQ = [] #quality control flag\n",
    "boxB = [] #backscatter\n",
    "boxWS = [] #wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latmin = -18.0\n",
    "latmax = -17.0  \n",
    "lonmin = 147.0\n",
    "lonmax = 148.0 \n",
    "\n",
    "if latmin>latmax:\n",
    "    print('Error wrong definition of min and max lat!!!')\n",
    "\n",
    "if lonmin>lonmax:\n",
    "    print('Error wrong definition of min and max lon!!!')\n",
    "\n",
    "\n",
    "\n",
    "start_date = dt.datetime(1985,1,1)\n",
    "end_date = dt.datetime(2019,2,21)\n",
    " \n",
    "#start_date = dt.datetime(2010,1,1)\n",
    "#end_date = dt.datetime(2010,12,31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2662\n"
     ]
    }
   ],
   "source": [
    "boxLat = [] #latitude\n",
    "boxLon = [] #longitude\n",
    "boxWh = [] #wave height\n",
    "boxT = [] #time\n",
    "boxQ = [] #quality control flag\n",
    "boxB = [] #backscatter\n",
    "boxWS = [] #wind Speed\n",
    "\n",
    "#urlON = allURL\n",
    "#print(len(urlON))\n",
    "newday_it = 0\n",
    "#for k in range(164,165):\n",
    "\n",
    "for u in range(len(allURL)):\n",
    "    urlON = allURL[u]\n",
    "    for k in range (len(urlON)):\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        lats = ncs.variables['LATITUDE'][:]\n",
    "        lons = ncs.variables['LONGITUDE'][:]\n",
    "        ws = ncs.variables['WSPD_CAL'][:]\n",
    "        \n",
    "        \n",
    "        if u == 2:\n",
    "            wh = ncs.variables['SWH_KA_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KA_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KA'][:]\n",
    "        \n",
    "        else:\n",
    "            wh = ncs.variables['SWH_KU_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KU_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KU'][:]\n",
    "            \n",
    "            \n",
    "            # Get desired time interval  \n",
    "            time_var = ncs.variables['TIME']\n",
    "            tt = ncs.variables['TIME'][:]\n",
    "            timing = netCDF4.num2date(tt,time_var.units)\n",
    "\n",
    "            #print(len(lats),len(ws),len(timing),len(qc),qc.min(),qc.max())\n",
    "            newday_it = 0\n",
    "            if lats.min() >= latmin and lats.min() <= latmax:\n",
    "                if lons.min() >= lonmin and lons.min() <= lonmax:\n",
    "                    for p in range(len(timing)):\n",
    "                        if timing[p] >= start_date and timing[p] <= end_date:\n",
    "                            if wh[p]>0 and qc[p]==1:\n",
    "\n",
    "                                t1 = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "        #                         print t1\n",
    "                                if newday_it == 0:\n",
    "                                    dd = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "                                    newday_it = p\n",
    "                                else:\n",
    "                                    if t1.day != dd.day:\n",
    "                                        boxLat.append(np.mean(lats[newday_it:p]))   \n",
    "        #                                 print newday_it,p\n",
    "                                        \n",
    "                                        dd = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "                                        boxLon.append(np.mean(lons[newday_it:p]))\n",
    "                                        boxWh.append(np.mean(wh[newday_it:p]))\n",
    "                                        boxT.append(np.mean(tt[newday_it:p]))\n",
    "                                        boxB.append(np.mean(back[newday_it:p]))\n",
    "                                        boxWS.append(np.mean(ws[newday_it:p]))\n",
    "                                        boxQ.append(np.mean(qc[newday_it:p]))   \n",
    "                                        newday_it = p\n",
    "\n",
    "        #                 print(lats.min(),lats.max(),lons.min(),lons.max())\n",
    "    #                 if timing[p] >= start_date and timing[p] <= end_date:\n",
    "    #                     print \n",
    "    #     if latmin >= lats.min() and latmax <= lats.min():\n",
    "#     for p in range(len(timing)):\n",
    "#         if timing[p] >= start_date and timing[p] <= end_date:\n",
    "#             if lats[p]>latmin and lats[p]<latmax and lons[p]>lonmin and lons[p]<lonmax:\n",
    "print len(boxLat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2662"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(boxQ)\n",
    "len(boxLat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(boxLat)):\n",
    "    if k == 0:\n",
    "        lat = boxLat[k]\n",
    "        lon = boxLon[k]\n",
    "        wh = boxWh[k]\n",
    "        tt = boxT[k]\n",
    "        qc = boxQ[k]\n",
    "        back = boxB[k]\n",
    "        ws = boxWS[k]\n",
    "    else:\n",
    "        lat = np.append(lat,boxLat[k])\n",
    "        lon = np.append(lon,boxLon[k])\n",
    "        wh = np.append(wh,boxWh[k])\n",
    "        tt = np.append(tt,boxT[k])\n",
    "        qc = np.append(qc,boxQ[k])\n",
    "        back = np.append(back,boxB[k])\n",
    "        ws = np.append(ws,boxWS[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'lat':lat.flatten(),\n",
    "     'lon':lon.flatten(),\n",
    "     'wh':wh.flatten(),\n",
    "     'tt':tt.flatten(),\n",
    "     'qc':qc.flatten(),\n",
    "     'back':back.flatten(),\n",
    "     'ws':ws.flatten()\n",
    "    })\n",
    "nameCSV = 'innis_1.csv'\n",
    "df.to_csv(str(nameCSV),columns=['lat', 'lon', 'wh', 'tt', 'qc', 'back','ws'], sep=' ', index=False ,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
