{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.tri as Tri\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "import netCDF4\n",
    "from netCDF4 import num2date, date2num, date2index\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from StringIO import StringIO\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractURLsatellite(fileURL, satName):\n",
    "    \"\"\"\n",
    "    Function to extract the URLs for a specific satellite from the IMOS URLs list\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - fileURL : IMOS URLs list as a txt file\n",
    "    - satName : name of the satellite such as JASON-2 JASON-3 \n",
    "    \n",
    "    Ouputs:\n",
    "    ------\n",
    "    \n",
    "    - getFiles : list of URLs for the desired satellite\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    getFiles = []\n",
    "    \n",
    "    with open(fileURL) as f:\n",
    "        for line in f:\n",
    "            if re.search(r\"%s\"%satName, line):\n",
    "                changeURL = re.sub('http://data.aodn.org.au', 'http://thredds.aodn.org.au/thredds/dodsC', line)\n",
    "                getFiles.append(changeURL)\n",
    "                \n",
    "    return getFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jason2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-2')\n",
    "\n",
    "jason3URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-3')\n",
    "\n",
    "saralURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SARAL')\n",
    "\n",
    "sentinel3aURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SENTINEL-3A')\n",
    "\n",
    "cryosat2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'CRYOSAT-2')\n",
    "\n",
    "enviURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ENVISAT')\n",
    "\n",
    "geosatURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GEOSAT')\n",
    "\n",
    "ersURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ERS-2')\n",
    "\n",
    "gfoURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GFO')\n",
    "\n",
    "topURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'TOPEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allURL = []\n",
    "allURL.append(jason2URL)\n",
    "allURL.append(jason3URL)\n",
    "allURL.append(saralURL)\n",
    "allURL.append(sentinel3aURL)\n",
    "allURL.append(cryosat2URL)\n",
    "allURL.append(enviURL)\n",
    "allURL.append(geosatURL)\n",
    "allURL.append(ersURL)\n",
    "allURL.append(gfoURL)\n",
    "allURL.append(topURL)\n",
    "\n",
    "boxLat = []\n",
    "boxLon = []\n",
    "boxWh = []\n",
    "boxT = []\n",
    "boxQ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latmin = -17.99 \n",
    "latmax = -16 \n",
    "lonmin = 147.0  \n",
    "lonmax = 148.99  \n",
    "\n",
    "if latmin>latmax:\n",
    "    print('Error wrong definition of min and max lat!!!')\n",
    "\n",
    "if lonmin>lonmax:\n",
    "    print('Error wrong definition of min and max lon!!!')\n",
    "\n",
    "\n",
    "\n",
    "start_date = dt.datetime(1985,1,1)\n",
    "end_date = dt.datetime(2019,2,21)\n",
    "\n",
    "#start_date = dt.datetime(2010,1,1)\n",
    "#end_date = dt.datetime(2010,12,31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in range(len(allURL)):\n",
    "    urlON = allURL[u]\n",
    "    for k in range (len(urlON)):\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        lats = ncs.variables['LATITUDE'][:]\n",
    "        lons = ncs.variables['LONGITUDE'][:]   \n",
    "        if u == 2:\n",
    "            wh = ncs.variables['SWH_KA_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KA_quality_control'][:]\n",
    "        \n",
    "        else:\n",
    "            wh = ncs.variables['SWH_KU_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KU_quality_control'][:]\n",
    "            \n",
    "        # Get desired time interval  \n",
    "        time_var = ncs.variables['TIME']\n",
    "        tt = ncs.variables['TIME'][:]\n",
    "        timing = netCDF4.num2date(tt,time_var.units)\n",
    "        \n",
    "        #data in correct time, quality flag and lat/lon\n",
    "        for p in range(len(timing)):\n",
    "            #print(u,' - ',k,'/',len(urlON),' - ',p,'/',len(timing))\n",
    "            if timing[p] >= start_date and timing[p] <= end_date:\n",
    "                if lats[p]>latmin and lats[p]<latmax and lons[p]>lonmin and lons[p]<lonmax:\n",
    "                    if np.where(np.logical_and(wh[p]>0,qc[p]==1)):\n",
    "                        boxLat.append(lats[p])\n",
    "                        boxLon.append(lons[p])\n",
    "                        boxWh.append(wh[p])\n",
    "                        boxT.append(tt[p])\n",
    "                        boxQ.append(qc[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(boxLat)):\n",
    "    if k == 0:\n",
    "        lat = boxLat[k]\n",
    "        lon = boxLon[k]\n",
    "        wh = boxWh[k]\n",
    "        tt = boxT[k]\n",
    "        qc = boxQ[k]\n",
    "    else:\n",
    "        lat = np.append(lat,boxLat[k])\n",
    "        lon = np.append(lon,boxLon[k])\n",
    "        wh = np.append(wh,boxWh[k])\n",
    "        tt = np.append(tt,boxT[k])\n",
    "        qc = np.append(qc,boxQ[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'lat':lat.flatten(),\n",
    "     'lon':lon.flatten(),\n",
    "     'wh':wh.flatten(),\n",
    "     'tt':tt.flatten(),\n",
    "     'qc':qc.flatten()\n",
    "    })\n",
    "nameCSV = 'innisfail_file.csv'\n",
    "df.to_csv(str(nameCSV),columns=['lat', 'lon', 'wh', 'tt', 'qc'], sep=' ', index=False ,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(str('help'), sep=r'\\s+', engine='c', header=None, na_filter=False, \\\n",
    "                                  # dtype=np.float, low_memory=False)\n",
    "nameCSV = 'innisfail_file.csv'\n",
    "data= pd.read_csv(str(nameCSV), sep=r'\\s+', engine='c', header=0, na_filter=False, \\\n",
    "                               dtype=np.float, low_memory=False)\n",
    "\n",
    "lat = data.values[:,0]\n",
    "lon = data.values[:,1]\n",
    "wh = data.values[:,2]\n",
    "tt = data.values[:,3]\n",
    "qc = data.values[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.345001220703125\n",
      "28.362001419067386\n",
      "21.00700187683105\n",
      "23.207000732421875\n",
      "22.24700164794922\n",
      "22.306001663208008\n",
      "22.29300117492676\n",
      "23.23900032043457\n",
      "21.66200065612793\n",
      "21.136001586914066\n",
      "21.374000549316406\n",
      "21.251001358032227\n",
      "20.554000854492188\n",
      "20.696001052856445\n",
      "21.117000579833984\n",
      "21.38900184631348\n",
      "21.13800048828125\n",
      "21.517000198364254\n",
      "20.218000411987305\n",
      "21.500001907348636\n",
      "22.00400161743164\n",
      "20.356000900268555\n",
      "21.769001007080078\n",
      "20.33700180053711\n",
      "21.952001571655273\n",
      "20.213001251220703\n",
      "21.178001403808594\n",
      "22.35900115966797\n",
      "21.61100196838379\n",
      "22.125001907348636\n",
      "22.750001907348636\n",
      "20.24100112915039\n",
      "21.04600143432617\n",
      "23.23300170898437\n",
      "20.538000106811523\n",
      "20.75900077819824\n",
      "21.23300170898437\n",
      "23.06800079345703\n",
      "22.21600151062012\n",
      "24.29700088500977\n",
      "22.612001419067386\n",
      "20.52400016784668\n",
      "22.446001052856445\n",
      "22.099000930786133\n",
      "21.18000030517578\n",
      "24.779001235961914\n",
      "21.211000442504886\n",
      "22.41800117492676\n",
      "22.088001251220703\n",
      "20.91400146484375\n",
      "23.47500038146973\n",
      "22.916000366210934\n",
      "22.645000457763672\n",
      "21.530000686645508\n",
      "22.63900184631348\n",
      "20.04600143432617\n",
      "23.26300048828125\n",
      "21.26000022888184\n",
      "21.792001724243164\n",
      "20.689001083374023\n",
      "20.08400154113769\n",
      "20.963001251220703\n",
      "20.310001373291016\n",
      "21.207000732421875\n",
      "22.097000122070312\n",
      "21.84600067138672\n",
      "23.79700088500977\n",
      "22.617000579833984\n",
      "22.06700134277344\n",
      "22.60800170898437\n",
      "21.23300170898437\n",
      "23.83700180053711\n",
      "21.205001831054688\n",
      "21.63900184631348\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(wh)):\n",
    "    if wh[k]>20:\n",
    "        print wh[k], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max(wh)\n",
    "netCDF4.num2date,time_var.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(wh)\n",
    "print len(lat)\n",
    "print len(lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [] #daystart\n",
    "for k in range(len(wh)):\n",
    "       \n",
    "    t1 = netCDF4.num2date(wh[k],time_var.units)\n",
    "    if k == 0: #get day 0. Then else: every day after that\n",
    "        days.append(0)\n",
    "        dd = netCDF4.num2date(wh[k],time_var.units)\n",
    "        it = 0\n",
    "    else:\n",
    "        if t1.day != dd.day: #if day 1 is not equal to day 2, then append\n",
    "            #print dd.day,t1.day\n",
    "            days.append(k)\n",
    "            it += 1\n",
    "            dd = netCDF4.num2date(wh[k],time_var.units)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_ = wh[days]\n",
    "qc_ = qc[days]\n",
    "lon_ = lon[days]\n",
    "tt_ = tt[days]\n",
    "lat_=lat[days]\n",
    "\n",
    "print len(whpos), 'whpos'\n",
    "print len(qc_),'qc_'\n",
    "print len(lon_),'lon_'\n",
    "print len(tt_),'tt_'\n",
    "print len(lat_),'lat_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'new days'\n",
    "\n",
    "print 'mean whpos', np.mean(wh_)\n",
    "print 'max whpos',max(wh_)\n",
    "print 'min whpos', min (wh_)\n",
    "\n",
    "print 'min lon',min(lon_)\n",
    "print 'min lon',min(lon_)\n",
    "print 'max lon',max(lon_)\n",
    "\n",
    "print 'min lat', min(lat_)\n",
    "print 'max lat',max(lat_)\n",
    "\n",
    "print min(netCDF4.num2date(tt_,time_var.units))\n",
    "print max (netCDF4.num2date(tt_,time_var.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
