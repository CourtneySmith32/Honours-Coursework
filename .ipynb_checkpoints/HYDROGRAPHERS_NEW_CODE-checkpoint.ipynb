{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.tri as Tri\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "import netCDF4\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from StringIO import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractURLsatellite(fileURL, satName):\n",
    "    \"\"\"\n",
    "    Function to extract the URLs for a specific satellite from the IMOS URLs list\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - fileURL : IMOS URLs list as a txt file\n",
    "    - satName : name of the satellite such as JASON-2 JASON-3 \n",
    "    \n",
    "    Ouputs:\n",
    "    ------\n",
    "    \n",
    "    - getFiles : list of URLs for the desired satellite\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    getFiles = []\n",
    "    \n",
    "    with open(fileURL) as f:\n",
    "        for line in f:\n",
    "            if re.search(r\"%s\"%satName, line):\n",
    "                changeURL = re.sub('http://data.aodn.org.au', 'http://thredds.aodn.org.au/thredds/dodsC', line)\n",
    "                getFiles.append(changeURL)\n",
    "                \n",
    "    return getFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jason2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-2')\n",
    "\n",
    "jason3URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-3')\n",
    "\n",
    "saralURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SARAL')\n",
    "\n",
    "sentinel3aURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SENTINEL-3A')\n",
    "\n",
    "cryosat2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'CRYOSAT-2')\n",
    "\n",
    "enviURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ENVISAT')\n",
    "\n",
    "geosatURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GEOSAT')\n",
    "\n",
    "ersURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ERS-2')\n",
    "\n",
    "gfoURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GFO')\n",
    "\n",
    "topURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'TOPEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allURL = []\n",
    "allURL.append(jason2URL)\n",
    "allURL.append(jason3URL)\n",
    "allURL.append(saralURL)\n",
    "allURL.append(sentinel3aURL)\n",
    "allURL.append(cryosat2URL)\n",
    "allURL.append(enviURL)\n",
    "allURL.append(geosatURL)\n",
    "allURL.append(ersURL)\n",
    "allURL.append(gfoURL)\n",
    "allURL.append(topURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n",
      "  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7f5bca940bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallURL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdtime2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"days since 1985-01-01 00:00:00 UTC\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gregorian'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdtime2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcftime/_cftime.pyx\u001b[0m in \u001b[0;36mcftime._cftime.num2date\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "ncs = allURL[0]\n",
    "dtime2 = netCDF4.num2date(ncs[0:],units = \"days since 1985-01-01 00:00:00 UTC\", calendar='gregorian')\n",
    "print dtime2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxLat = []\n",
    "boxLon = []\n",
    "boxWh = []\n",
    "boxT = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cyclone coordinates for marcia\n",
    "latmin = -19.0\n",
    "latmax = -18.0  \n",
    "lonmin = 150.0 \n",
    "lonmax = 151.0\n",
    "\n",
    "if latmin>latmax:\n",
    "    print('Error wrong definition of min and max lat!!!')\n",
    "\n",
    "if lonmin>lonmax:\n",
    "    print('Error wrong definition of min and max lon!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marcia dates\n",
    "start_date = dt.datetime(1985,1,1)\n",
    "end_date = dt.datetime(2019,2,21)\n",
    "\n",
    "#start_date = dt.datetime(2010,1,1)\n",
    "#end_date = dt.datetime(2010,12,31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for u in range (len(allURL)):\n",
    "    urlON = allURL[u]\n",
    "    for k in range (len(urlON)):\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        lats = ncs.variables['LATITUDE'][:]\n",
    "        lons = ncs.variables['LONGITUDE'][:]\n",
    "        if u == 2:\n",
    "            wh = ncs.variables['SWH_KA_CAL'][:]\n",
    "        else:\n",
    "            wh = ncs.variables['SWH_KU_CAL'][:]\n",
    "\n",
    "        # Get desired time interval  \n",
    "        time_var = ncs.variables['TIME']\n",
    "        tt = ncs.variables['TIME'][:]\n",
    "        \n",
    "        timing = netCDF4.num2date(tt,time_var.units)\n",
    "        \n",
    "        \n",
    "        for k in range(len(timing)):\n",
    "            if timing[k] >= start_date and timing[k] <= end_date:\n",
    "                if lats[k]>latmin and lats[k]<latmax and lons[k]>lonmin and lons[k]<lonmax:\n",
    "                    boxLat.append(lats[k])\n",
    "                    boxLon.append(lons[k])\n",
    "                    boxWh.append(wh[k])\n",
    "                    boxT.append(tt[k])\n",
    "                    #print timing[k]\n",
    "                    \n",
    "#         id_2 = netCDF4.date2index(end_date,time_var,select='nearest')\n",
    "#         diff3 = start_date-netCDF4.num2date(tt[id_2],time_var.units)\n",
    "        \n",
    "#         diff2 = end_date-netCDF4.num2date(tt[id_2],time_var.units)\n",
    "        #dh1 = (diff1.seconds + diff1.days * 24 * 3600)/3600.\n",
    "#         dh2 = (diff2.seconds + diff2.days * 24 * 3600)/3600. #diff in end date (actual vs nearest) in days\n",
    "#         dh3 = (diff3.seconds + diff3.days * 24 * 3600)/3600. #diff btn start date and nearest end date in days\n",
    "\n",
    "#         id_st = -1\n",
    "#         id_et = -1\n",
    "#         if dh3<0.:\n",
    "#             id_st = netCDF4.date2index(start_date,time_var,select='after')\n",
    "            \n",
    "#         if dh2>-24.:\n",
    "#             id_et = netCDF4.date2index(end_date,time_var,select='before')\n",
    "            \n",
    "#         if id_st<id_et:\n",
    "#             print id_st,id_et,netCDF4.num2date(tt[id_st],time_var.units)\n",
    "#             print netCDF4.num2date(tt[id_et],time_var.units)\n",
    "#             # Check if satellite points are in the box\n",
    "#             id1 = lats>latmin\n",
    "#             id2 = lats<latmax\n",
    "#             id3 = lons>lonmin\n",
    "#             id4 = lons<lonmax\n",
    "#             id1 = id1*1\n",
    "#             id2 = id2*1\n",
    "#             id3 = id3*1\n",
    "#             id4 = id4*1\n",
    "#             tot = id1+id2+id3+id4\n",
    "            \n",
    "#             # If this is the case then the sum should be 4\n",
    "#             inside = np.where(tot==4)[0]\n",
    "#             idtime = np.arange(id_st,id_et+1)\n",
    "\n",
    "#             idin = np.intersect1d(inside, idtime)\n",
    "\n",
    "#             if len(idin)>0:\n",
    "#                 boxLat.append(lats[idin])\n",
    "#                 boxLon.append(lons[idin])\n",
    "#                 boxWh.append(wh[idin])\n",
    "#                 boxT.append(tt[idin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38151"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boxT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(boxLat)):\n",
    "    if k == 0:\n",
    "        lat = boxLat[k]\n",
    "        lon = boxLon[k]\n",
    "        wh = boxWh[k]\n",
    "        tt = boxT[k]\n",
    "    else:\n",
    "        lat = np.append(lat,boxLat[k])\n",
    "        lon = np.append(lon,boxLon[k])\n",
    "        wh = np.append(wh,boxWh[k])\n",
    "        tt = np.append(tt,boxT[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "masked_array(data=[2.19800019, 2.19800019, 2.22200012, ..., 0.88600004,\n",
       "                   0.88600004, 0.78000003],\n",
       "             mask=False,\n",
       "       fill_value=1e+20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(wh)\n",
    "wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records for Hydrographers: 38151\n"
     ]
    }
   ],
   "source": [
    "print 'records for Hydrographers:', len(boxWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38015"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wave height pos values\n",
    "\n",
    "ids = np.where(wh>0)[0]\n",
    "whpos = wh[ids]\n",
    "len(whpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5434551306822604\n"
     ]
    }
   ],
   "source": [
    "print np.mean(whpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean whpos 1.5434551306822604\n",
      "max whpos 28.41200065612793\n",
      "min whpos 0.004000000189989805\n",
      "mean wave height 1.537953049537001\n",
      "min lon 150.00024\n",
      "max lon 150.99998\n",
      "min lat -18.999968\n",
      "max lat -18.00001\n",
      "1985-04-09 08:39:51.945317\n",
      "1985-04-09 08:39:51.945317\n",
      "2019-02-17 15:25:05.484371\n",
      "2019-02-17 15:25:05.484371\n"
     ]
    }
   ],
   "source": [
    "print 'mean whpos', np.mean(whpos)\n",
    "print 'max whpos',max(whpos)\n",
    "print 'min whpos', min (whpos)\n",
    "\n",
    "#try diff wave names\n",
    "print 'mean wave height', np.mean(wh)\n",
    "\n",
    "print 'min lon',min(lon)\n",
    "print 'max lon',max(lon)\n",
    "\n",
    "print 'min lat', min(lat)\n",
    "print 'max lat',max(lat)\n",
    "\n",
    "print min(netCDF4.num2date(tt,time_var.units))\n",
    "print min (netCDF4.num2date(tt[ids],time_var.units))\n",
    "print max (netCDF4.num2date(tt,time_var.units))\n",
    "print max (netCDF4.num2date(tt[ids],time_var.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(tt)):\n",
    "    if wh[k]>0:\n",
    "        print netCDF4.num2date(tt[k],time_var.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsort = np.sort(tt)\n",
    "for k in range(len(tsort)):\n",
    "    print netCDF4.num2date(tsort[k],time_var.units)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
