{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.tri as Tri\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "import netCDF4\n",
    "from netCDF4 import num2date, date2num, date2index\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from StringIO import StringIO\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractURLsatellite(fileURL, satName):\n",
    "    \"\"\"\n",
    "    Function to extract the URLs for a specific satellite from the IMOS URLs list\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - fileURL : IMOS URLs list as a txt file\n",
    "    - satName : name of the satellite such as JASON-2 JASON-3 \n",
    "    \n",
    "    Ouputs:\n",
    "    ------\n",
    "    \n",
    "    - getFiles : list of URLs for the desired satellite\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    getFiles = []\n",
    "    \n",
    "    with open(fileURL) as f:\n",
    "        for line in f:\n",
    "            if re.search(r\"%s\"%satName, line):\n",
    "                changeURL = re.sub('http://data.aodn.org.au', 'http://thredds.aodn.org.au/thredds/dodsC', line)\n",
    "                getFiles.append(changeURL)\n",
    "                \n",
    "    return getFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jason2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-2')\n",
    "\n",
    "jason3URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-3')\n",
    "\n",
    "saralURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SARAL')\n",
    "\n",
    "sentinel3aURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SENTINEL-3A')\n",
    "\n",
    "cryosat2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'CRYOSAT-2')\n",
    "\n",
    "enviURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ENVISAT')\n",
    "\n",
    "geosatURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GEOSAT')\n",
    "\n",
    "ersURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ERS-2')\n",
    "\n",
    "gfoURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GFO')\n",
    "\n",
    "topURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'TOPEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allURL = []\n",
    "allURL.append(jason2URL)\n",
    "allURL.append(jason3URL)\n",
    "allURL.append(saralURL)\n",
    "allURL.append(sentinel3aURL)\n",
    "allURL.append(cryosat2URL)\n",
    "allURL.append(enviURL)\n",
    "allURL.append(geosatURL)\n",
    "allURL.append(ersURL)\n",
    "allURL.append(gfoURL)\n",
    "allURL.append(topURL)\n",
    "\n",
    "boxLat = [] #latitude\n",
    "boxLon = [] #longitude\n",
    "boxWh = [] #wave height\n",
    "boxT = [] #time\n",
    "boxQ = [] #quality control flag\n",
    "boxB = [] #backscatter\n",
    "boxWS = [] #wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latmin = -24.0 \n",
    "latmax = -23.0  \n",
    "lonmin = 153.0 \n",
    "lonmax = 154.0 \n",
    "\n",
    "\n",
    "if latmin>latmax:\n",
    "    print('Error wrong definition of min and max lat!!!')\n",
    "\n",
    "if lonmin>lonmax:\n",
    "    print('Error wrong definition of min and max lon!!!')\n",
    "\n",
    "\n",
    "\n",
    "start_date = dt.datetime(1985,1,1)\n",
    "end_date = dt.datetime(2019,2,21)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2585\n"
     ]
    }
   ],
   "source": [
    "boxLat = [] #latitude\n",
    "boxLon = [] #longitude\n",
    "boxWh = [] #wave height\n",
    "boxT = [] #time\n",
    "boxQ = [] #quality control flag\n",
    "boxB = [] #backscatter\n",
    "boxWS = [] #wind Speed\n",
    "\n",
    "#urlON = allURL\n",
    "#print(len(urlON))\n",
    "newday_it = 0\n",
    "#for k in range(164,165):\n",
    "\n",
    "\n",
    "for u in range(len(allURL)):\n",
    "    urlON = allURL[u]\n",
    "    for k in range (len(urlON)):\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        lats = ncs.variables['LATITUDE'][:]\n",
    "        lons = ncs.variables['LONGITUDE'][:]\n",
    "        ws = ncs.variables['WSPD_CAL'][:]\n",
    "        \n",
    "        if u == 2:\n",
    "            wh = ncs.variables['SWH_KA_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KA_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KA'][:]\n",
    "        \n",
    "        else:\n",
    "            wh = ncs.variables['SWH_KU_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KU_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KU'][:]\n",
    "        \n",
    "        # Get desired time interval  \n",
    "        \n",
    "        \n",
    "        time_var = ncs.variables['TIME']\n",
    "        tt = ncs.variables['TIME'][:]\n",
    "        timing = netCDF4.num2date(tt,time_var.units)\n",
    "        #print(len(lats),len(ws),len(timing),len(qc),qc.min(),qc.max())\n",
    "        #newday_it = 0\n",
    "      \n",
    "        if lats.min() >= latmin and lats.min() <= latmax:\n",
    "            if lons.min() >= lonmin and lons.min() <= lonmax:\n",
    "                for p in range(len(timing)):\n",
    "                    if timing[p] >= start_date and timing[p] <= end_date:\n",
    "                        if wh[p]>0 and qc[p]==1:\n",
    "                            t1 = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "    #                         print t1\n",
    "                            if newday_it == 0:\n",
    "                                dd = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "                                newday_it = p\n",
    "                            else:\n",
    "                                if t1.day != dd.day:  \n",
    "                                    newday_it = p\n",
    "                                    dd = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "                                    boxLat.append(np.mean(lats[newday_it:p])) \n",
    "                                    boxLon.append(np.mean(lons[newday_it:p]))   \n",
    "                                    boxWh.append(np.mean(wh[newday_it:p]))   \n",
    "                                    boxT.append(np.mean(tt[newday_it:p]))   \n",
    "                                    boxQ.append(np.mean(qc[newday_it:p]))   \n",
    "                                    boxB.append(np.mean(back[newday_it:p]))\n",
    "                                    boxWS.append(np.mean(ws[newday_it:p]))   \n",
    "    #                         \n",
    "    \n",
    "    \n",
    "    #                         boxLon.append(np.mean(lons[p]))\n",
    "    #                                 boxWh.append(np.mean(wh[p]))\n",
    "    #                                 boxT.append(np.mean(tt[p]))\n",
    "    #                                 boxB.append(np.mean(back[p]))\n",
    "    #                                 boxWS.append(np.mean(ws[p]))\n",
    "    #                                 boxQ.append(np.mean(qc[p]))   \n",
    "    #                 print(lats.min(),lats.max(),lons.min(),lons.max())\n",
    "    #                 if timing[p] >= start_date and timing[p] <= end_date:\n",
    "    #                     print \n",
    "    #     if latmin >= lats.min() and latmax <= lats.min():\n",
    "    #     for p in range(len(timing)):\n",
    "    #         if timing[p] >= start_date and timing[p] <= end_date:\n",
    "    #             if lats[p]>latmin and lats[p]<latmax and lons[p]>lonmin and lons[p]<lonmax:\n",
    "print len(boxLat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(boxLat)):\n",
    "    if k == 0:\n",
    "        lat = boxLat[k]\n",
    "        lon = boxLon[k]\n",
    "        wh = boxWh[k]\n",
    "        tt = boxT[k]\n",
    "        qc = boxQ[k]\n",
    "        back = boxB[k]\n",
    "        ws = boxWS[k]\n",
    "    else:\n",
    "        lat = np.append(lat,boxLat[k])\n",
    "        lon = np.append(lon,boxLon[k])\n",
    "        wh = np.append(wh,boxWh[k])\n",
    "        tt = np.append(tt,boxT[k])\n",
    "        qc = np.append(qc,boxQ[k])\n",
    "        back = np.append(back,boxB[k])\n",
    "        ws = np.append(ws,boxWS[k])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2585"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boxLat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'lat':lat.flatten(),\n",
    "     'lon':lon.flatten(),\n",
    "     'wh':wh.flatten(),\n",
    "     'tt':tt.flatten(),\n",
    "     'qc':qc.flatten(),\n",
    "     'back':back.flatten(),\n",
    "     'ws':ws.flatten()\n",
    "    })\n",
    "nameCSV = 'innis_day.csv'\n",
    "df.to_csv(str(nameCSV),columns=['lat', 'lon', 'wh', 'tt', 'qc', 'back','ws'], sep=' ', index=False ,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7171, 7171, 7171, 7171, 1, 4)\n",
      "(7376, 7376, 7376, 7376, 1, 4)\n",
      "(13059, 13059, 13059, 13059, 1, 4)\n",
      "(3476, 3476, 3476, 3476, 2, 4)\n",
      "(6663, 6663, 6663, 6663, 1, 4)\n",
      "(6586, 6586, 6586, 6586, 1, 4)\n",
      "(4577, 4577, 4577, 4577, 1, 4)\n",
      "(7992, 7992, 7992, 7992, 1, 4)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4d4c1cf2ad25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0murlON\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallURL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetCDFFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlON\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetCDFFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlON\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LATITUDE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._get_types\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/bgh2-ra/anaconda2/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Each link is stored as a list of length three:  [PREV, NEXT, KEY].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         '''Initialize an ordered dictionary.  The signature is the same as\n\u001b[1;32m     52\u001b[0m         \u001b[0mregular\u001b[0m \u001b[0mdictionaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecommended\u001b[0m \u001b[0mbecause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### OLD VERSION\n",
    "\n",
    "boxLat = [] #latitude\n",
    "boxLon = [] #longitude\n",
    "boxWh = [] #wave height\n",
    "boxT = [] #time\n",
    "boxQ = [] #quality control flag\n",
    "boxB = [] #backscatter\n",
    "boxWS = [] #wind Speed\n",
    "\n",
    "#urlON = allURL\n",
    "#print(len(urlON))\n",
    "newday_it = 0\n",
    "#for k in range(164,165):\n",
    "\n",
    "for u in range(len(allURL)):\n",
    "    urlON = allURL[u]\n",
    "    for k in range (len(urlON)):\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        lats = ncs.variables['LATITUDE'][:]\n",
    "        lons = ncs.variables['LONGITUDE'][:]\n",
    "        ws = ncs.variables['WSPD_CAL'][:]\n",
    "        qc = ncs.variables['SWH_KU_quality_control'][:]\n",
    "        wh = ncs.variables['SWH_KU_CAL'][:]\n",
    "\n",
    "        # Get desired time interval  \n",
    "        time_var = ncs.variables['TIME']\n",
    "        tt = ncs.variables['TIME'][:]\n",
    "        timing = netCDF4.num2date(tt,time_var.units)\n",
    "\n",
    "        print(len(lats),len(ws),len(timing),len(qc),qc.min(),qc.max())\n",
    "        newday_it = 0\n",
    "        if lats.min() >= latmin and lats.min() <= latmax:\n",
    "            if lons.min() >= lonmin and lons.min() <= lonmax:\n",
    "                for p in range(len(timing)):\n",
    "                    if timing[p] >= start_date and timing[p] <= end_date:\n",
    "                        if wh[p]>0 and qc[p]==1:\n",
    "\n",
    "                            t1 = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "    #                         print t1\n",
    "                            if newday_it == 0:\n",
    "                                dd = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "                                newday_it = p\n",
    "                            else:\n",
    "                                if t1.day != dd.day:\n",
    "                                    boxLat.append(np.mean(lats[newday_it:p]))   \n",
    "    #                                 print newday_it,p\n",
    "                                    newday_it = p\n",
    "                                    dd = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "\n",
    "\n",
    "\n",
    "    #                         boxLat.append(lats[p])\n",
    "    #                         boxLon.append(np.mean(lons[p]))\n",
    "    #                                 boxWh.append(np.mean(wh[p]))\n",
    "    #                                 boxT.append(np.mean(tt[p]))\n",
    "    #                                 boxB.append(np.mean(back[p]))\n",
    "    #                                 boxWS.append(np.mean(ws[p]))\n",
    "    #                                 boxQ.append(np.mean(qc[p]))   \n",
    "\n",
    "    #                 print(lats.min(),lats.max(),lons.min(),lons.max())\n",
    "    #                 if timing[p] >= start_date and timing[p] <= end_date:\n",
    "    #                     print \n",
    "    #     if latmin >= lats.min() and latmax <= lats.min():\n",
    "#     for p in range(len(timing)):\n",
    "#         if timing[p] >= start_date and timing[p] <= end_date:\n",
    "#             if lats[p]>latmin and lats[p]<latmax and lons[p]>lonmin and lons[p]<lonmax:\n",
    "print len(boxLat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in range(len(allURL)):\n",
    "    urlON = allURL[u]\n",
    "    for k in range (len(urlON)):\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        lats = ncs.variables['LATITUDE'][:]\n",
    "        lons = ncs.variables['LONGITUDE'][:]\n",
    "        ws = ncs.variables['WSPD_CAL'][:]\n",
    "        \n",
    "        if u == 2:\n",
    "            wh = ncs.variables['SWH_KA_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KA_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KA'][:]\n",
    "        \n",
    "        else:\n",
    "            wh = ncs.variables['SWH_KU_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KU_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KU'][:]\n",
    "            \n",
    "        # Get desired time interval  \n",
    "        time_var = ncs.variables['TIME']\n",
    "        tt = ncs.variables['TIME'][:]\n",
    "        timing = netCDF4.num2date(tt,time_var.units)\n",
    "        \n",
    "        #data in correct time, quality flag and lat/lon\n",
    "        for p in range(len(timing)):\n",
    "            #print(u,' - ',k,'/',len(urlON),' - ',p,'/',len(timing))\n",
    "            if timing[p] >= start_date and timing[p] <= end_date:\n",
    "                if lats[p]>latmin and lats[p]<latmax and lons[p]>lonmin and lons[p]<lonmax:\n",
    "                    if np.logical_and(wh[p]>0,qc[p]==1):\n",
    "                        t1 = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "                        kkk = 0\n",
    "                        if kkk == 0:\n",
    "                            dd = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "                            it = p\n",
    "                        else:\n",
    "                            if t1.day != dd.day:\n",
    "                                boxLat.append(np.mean(lats[it:p]))\n",
    "                                boxLon.append(np.mean(lons[p]))\n",
    "                                boxWh.append(np.mean(wh[p]))\n",
    "                                boxT.append(np.mean(tt[p]))\n",
    "                                boxB.append(np.mean(back[p]))\n",
    "                                boxWS.append(np.mean(ws[p]))\n",
    "                                boxQ.append(np.mean(qc[p]))               \n",
    "                        kkk = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(boxT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
