{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.tri as Tri\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "import netCDF4\n",
    "from netCDF4 import date2index\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from StringIO import StringIO\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractURLsatellite(fileURL, satName):\n",
    "    \"\"\"\n",
    "    Function to extract the URLs for a specific satellite from the IMOS URLs list\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - fileURL : IMOS URLs list as a txt file\n",
    "    - satName : name of the satellite such as JASON-2 JASON-3 \n",
    "    \n",
    "    Ouputs:\n",
    "    ------\n",
    "    \n",
    "    - getFiles : list of URLs for the desired satellite\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    getFiles = []\n",
    "    \n",
    "    with open(fileURL) as f:\n",
    "        for line in f:\n",
    "            if re.search(r\"%s\"%satName, line):\n",
    "                changeURL = re.sub('http://data.aodn.org.au', 'http://thredds.aodn.org.au/thredds/dodsC', line)\n",
    "                getFiles.append(changeURL)\n",
    "                \n",
    "    return getFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jason2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-2')\n",
    "\n",
    "jason3URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-3')\n",
    "\n",
    "saralURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SARAL')\n",
    "\n",
    "sentinel3aURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SENTINEL-3A')\n",
    "\n",
    "cryosat2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'CRYOSAT-2')\n",
    "\n",
    "enviURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ENVISAT')\n",
    "\n",
    "geosatURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GEOSAT')\n",
    "\n",
    "ersURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ERS-2')\n",
    "\n",
    "gfoURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GFO')\n",
    "\n",
    "topURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'TOPEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allURL = []\n",
    "allURL.append(jason2URL)\n",
    "allURL.append(jason3URL)\n",
    "allURL.append(saralURL)\n",
    "allURL.append(sentinel3aURL)\n",
    "allURL.append(cryosat2URL)\n",
    "allURL.append(enviURL)\n",
    "allURL.append(geosatURL)\n",
    "allURL.append(ersURL)\n",
    "allURL.append(gfoURL)\n",
    "allURL.append(topURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxLat = [] #latitude\n",
    "boxLon = [] #longitude\n",
    "boxWh = [] #wave height\n",
    "boxT = [] #time\n",
    "boxQ = [] #quality control flag\n",
    "boxB = [] #backscatter\n",
    "boxU = [] #wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cape Melville coordinates\n",
    "latmin = -14.0\n",
    "latmax = -13.0  \n",
    "lonmin = 145.0\n",
    "lonmax = 146.0\n",
    "\n",
    "if latmin>latmax:\n",
    "    print('Error wrong definition of min and max lat!!!')\n",
    "\n",
    "if lonmin>lonmax:\n",
    "    print('Error wrong definition of min and max lon!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "start_date = dt.datetime(1985,1,1)\n",
    "end_date = dt.datetime(2019,2,21)\n",
    "\n",
    "#start_date = dt.datetime(2010,1,1)\n",
    "#end_date = dt.datetime(2010,12,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for u in range (len(allURL)):\n",
    "    urlON = allURL[u]\n",
    "    for k in range (len(urlON)):\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        lats = ncs.variables['LATITUDE'][:]\n",
    "        lons = ncs.variables['LONGITUDE'][:]\n",
    "        ws = ncs.variables['WSPD_CAL'][:]\n",
    "       \n",
    "        if u == 2:\n",
    "            wh = ncs.variables['SWH_KA_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KA_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KA'][:]\n",
    "            \n",
    "        else:\n",
    "            wh = ncs.variables['SWH_KU_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KU_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KU'][:]\n",
    "\n",
    "            \n",
    "        # Get desired time interval  \n",
    "        time_var = ncs.variables['TIME']\n",
    "        tt = ncs.variables['TIME'][:]\n",
    "        \n",
    "        timing = netCDF4.num2date(tt,time_var.units)\n",
    "        \n",
    "        #data in correct time, quality flag and lat/lon\n",
    "        for k in range(len(timing)):\n",
    "            if timing[k] >= start_date and timing[k] <= end_date:\n",
    "                if lats[k]>latmin and lats[k]<latmax and lons[k]>lonmin and lons[k]<lonmax:\n",
    "                    boxLat.append(lats[k])\n",
    "                    boxLon.append(lons[k])\n",
    "                    boxWh.append(wh[k])\n",
    "                    boxT.append(tt[k])\n",
    "                    boxQ.append(qc[k])\n",
    "                    boxB.append(back[k])\n",
    "                    boxU.append(ws[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boxT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(boxLat)):\n",
    "    if k == 0:\n",
    "        lat = boxLat[k]\n",
    "        lon = boxLon[k]\n",
    "        wh = boxWh[k]\n",
    "        tt = boxT[k]\n",
    "        qc = boxQ[k]\n",
    "        back = boxB[k]\n",
    "        ws = boxU[k]\n",
    "    else:\n",
    "        lat = np.append(lat,boxLat[k])\n",
    "        lon = np.append(lon,boxLon[k])\n",
    "        wh = np.append(wh,boxWh[k])\n",
    "        tt = np.append(tt,boxT[k])\n",
    "        qc = np.append(qc,boxQ[k])\n",
    "        back = np.append(back,boxB[k])\n",
    "        ws = np.append(ws, boxU[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666\n"
     ]
    }
   ],
   "source": [
    "print len(wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34802 whpos\n"
     ]
    }
   ],
   "source": [
    "ids = np.where(np.logical_and(wh>0,qc==1))\n",
    "\n",
    "lat_ = lat[ids]\n",
    "lon_ = lon[ids]\n",
    "whpos = wh[ids]\n",
    "tt_ = tt[ids]\n",
    "qc_ = qc[ids]\n",
    "back_ = back[ids]\n",
    "ws_ = ws[ids]\n",
    "\n",
    "print len(whpos), 'whpos'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean whpos 1.6800049060284783\n",
      "max whpos 4.949000358581543\n",
      "min whpos 0.003000000026077032\n",
      "min lon 145.00002\n",
      "max lon 145.99998\n",
      "min lat -13.999892\n",
      "max lat -13.000028\n",
      "min backscatter 4.79\n",
      "max backscatter 28.01\n",
      "min ws 0.5600000023841858\n",
      "max ws 39.36000061035156\n",
      "start time 1985-04-05 21:27:22.624997\n",
      "end time 2019-02-20 11:53:11.406250\n"
     ]
    }
   ],
   "source": [
    "print 'mean whpos', np.mean(whpos)\n",
    "print 'max whpos',max(whpos)\n",
    "print 'min whpos', min (whpos)\n",
    "\n",
    "print 'min lon',min(lon_)\n",
    "print 'max lon',max(lon_)\n",
    "\n",
    "print 'min lat', min(lat_)\n",
    "print 'max lat',max(lat_)\n",
    "\n",
    "print 'min backscatter', min(back_)\n",
    "print 'max backscatter', max(back_)\n",
    "\n",
    "print 'min ws', min(ws_)\n",
    "print 'max ws', max(ws_)\n",
    "\n",
    "print 'start time', min(netCDF4.num2date(tt_,time_var.units))\n",
    "print 'end time', max (netCDF4.num2date(tt_,time_var.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(whpos)):\n",
    "    #if np.where(np.logical_and(wh>0,qc==1)):\n",
    "    print netCDF4.num2date(whpos[k],time_var.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(whpos)):\n",
    "    #if np.where(np.logical_and(wh>0,qc==1)):\n",
    "    print netCDF4.num2date(tt_[k],time_var.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted1 = np.sort(tt_)\n",
    "for k in range(len(sorted1)):\n",
    "    print netCDF4.num2date(sorted1[k],time_var.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAVE PERIOD EQN\n",
    "\n",
    "$ \\epsilon = 3.25 \\left( H_s^2 g^2/U^4 \\right)^{0.31}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wave age. g = 9.80665 m/s2.  ξ=3.25(H2sg2/U4)^0.31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[19.04380601, 16.61672076, 13.36446587, ...,\n",
       "                   11.33820514, 11.33820514,  8.93675939],\n",
       "             mask=False,\n",
       "       fill_value=1e+20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(whpos,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveage(H, U, grav=9.80665):\n",
    "    '''\n",
    "    The pseudo wave age can be expressed in terms of significant wave height and surface wind speed.\n",
    "    '''\n",
    "\n",
    "    grav2 = grav**2\n",
    "    hs2 = np.square(H) \n",
    "    u4 = np.power(U,4)\n",
    "    tmp = np.divide(hs2*grav2,u4)\n",
    "    eps = 3.25*np.power(tmp,0.31)\n",
    "    \n",
    "    return eps\n",
    "\n",
    "\n",
    "def waveperiod(H, U, grav=9.80665):\n",
    "    '''\n",
    "    blah blah\n",
    "    '''\n",
    "\n",
    "    eps = waveage(H, U, grav=9.80665)\n",
    "    period = (((eps-(5.78))/(eps+(U/(H*((U/H)+H)))))+(H+(5.70)))\n",
    "    \n",
    "    return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.38329868599818 5.243681379130724 5.135587000064403 ...\n",
      " 5.458391830570296 5.333780063288117 5.1881342515098074]\n",
      "34802\n"
     ]
    }
   ],
   "source": [
    "T = waveperiod(whpos,ws_)\n",
    "print T\n",
    "print len(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GA-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz = (((w_a-(5.78))/(w_a+(ws_/(whpos*((ws_/whpos)+whpos)))))+(whpos+(5.7)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
