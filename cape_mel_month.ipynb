{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.tri as Tri\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "import netCDF4\n",
    "from netCDF4 import num2date, date2num, date2index\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from StringIO import StringIO\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractURLsatellite(fileURL, satName):\n",
    "    \"\"\"\n",
    "    Function to extract the URLs for a specific satellite from the IMOS URLs list\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - fileURL : IMOS URLs list as a txt file\n",
    "    - satName : name of the satellite such as JASON-2 JASON-3 \n",
    "    \n",
    "    Ouputs:\n",
    "    ------\n",
    "    \n",
    "    - getFiles : list of URLs for the desired satellite\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    getFiles = []\n",
    "    \n",
    "    with open(fileURL) as f:\n",
    "        for line in f:\n",
    "            if re.search(r\"%s\"%satName, line):\n",
    "                changeURL = re.sub('http://data.aodn.org.au', 'http://thredds.aodn.org.au/thredds/dodsC', line)\n",
    "                getFiles.append(changeURL)\n",
    "                \n",
    "    return getFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jason2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-2')\n",
    "\n",
    "jason3URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-3')\n",
    "\n",
    "saralURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SARAL')\n",
    "\n",
    "sentinel3aURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SENTINEL-3A')\n",
    "\n",
    "cryosat2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'CRYOSAT-2')\n",
    "\n",
    "enviURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ENVISAT')\n",
    "\n",
    "geosatURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GEOSAT')\n",
    "\n",
    "ersURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ERS-2')\n",
    "\n",
    "gfoURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GFO')\n",
    "\n",
    "topURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'TOPEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allURL = []\n",
    "allURL.append(jason2URL)\n",
    "allURL.append(jason3URL)\n",
    "allURL.append(saralURL)\n",
    "allURL.append(sentinel3aURL)\n",
    "allURL.append(cryosat2URL)\n",
    "allURL.append(enviURL)\n",
    "allURL.append(geosatURL)\n",
    "allURL.append(ersURL)\n",
    "allURL.append(gfoURL)\n",
    "allURL.append(topURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxLat = []\n",
    "boxLon = []\n",
    "boxWh = []\n",
    "boxT = []\n",
    "boxQ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cape Melville coordinates\n",
    "latmin = -14.0\n",
    "latmax = -13.0  \n",
    "lonmin = 145.0\n",
    "lonmax = 146.0\n",
    "\n",
    "if latmin>latmax:\n",
    "    print('Error wrong definition of min and max lat!!!')\n",
    "\n",
    "if lonmin>lonmax:\n",
    "    print('Error wrong definition of min and max lon!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "start_date = dt.datetime(1985,1,1)\n",
    "end_date = dt.datetime(2019,2,21)\n",
    "\n",
    "#start_date = dt.datetime(2010,1,1)\n",
    "#end_date = dt.datetime(2010,12,31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for u in range (len(allURL)):\n",
    "    urlON = allURL[u]\n",
    "    for k in range (len(urlON)):\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        lats = ncs.variables['LATITUDE'][:]\n",
    "        lons = ncs.variables['LONGITUDE'][:]\n",
    "       \n",
    "        if u == 2:\n",
    "            wh = ncs.variables['SWH_KA_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KA_quality_control'][:]\n",
    "        \n",
    "        else:\n",
    "            wh = ncs.variables['SWH_KU_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KU_quality_control'][:]\n",
    "\n",
    "        # Get desired time interval  \n",
    "        time_var = ncs.variables['TIME']\n",
    "        tt = ncs.variables['TIME'][:]\n",
    "        \n",
    "        timing = netCDF4.num2date(tt,time_var.units)\n",
    "        \n",
    "        #data in correct time, quality flag and lat/lon\n",
    "        for k in range(len(timing)):\n",
    "            if timing[k] >= start_date and timing[k] <= end_date:\n",
    "                if lats[k]>latmin and lats[k]<latmax and lons[k]>lonmin and lons[k]<lonmax:\n",
    "                    boxLat.append(lats[k])\n",
    "                    boxLon.append(lons[k])\n",
    "                    boxWh.append(wh[k])\n",
    "                    boxT.append(tt[k])\n",
    "                    boxQ.append(qc[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boxT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(boxLat)):\n",
    "    if k == 0:\n",
    "        lat = boxLat[k]\n",
    "        lon = boxLon[k]\n",
    "        wh = boxWh[k]\n",
    "        tt = boxT[k]\n",
    "        qc = boxQ[k]\n",
    "    else:\n",
    "        lat = np.append(lat,boxLat[k])\n",
    "        lon = np.append(lon,boxLon[k])\n",
    "        wh = np.append(wh,boxWh[k])\n",
    "        tt = np.append(tt,boxT[k])\n",
    "        qc = np.append(qc,boxQ[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8586.98190086, 8586.98191262, 8586.98192455, ..., 6455.12111966,\n",
       "       6455.12113211, 6455.12114454])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt[0]\n",
    "boxT\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2008, 7, 5, 23, 33, 56, 234372)\n",
      " datetime.datetime(2008, 7, 5, 23, 33, 57, 249997)\n",
      " datetime.datetime(2008, 7, 5, 23, 33, 58, 281253) ...\n",
      " datetime.datetime(2002, 9, 4, 2, 54, 24, 738280)\n",
      " datetime.datetime(2002, 9, 4, 2, 54, 25, 814456)\n",
      " datetime.datetime(2002, 9, 4, 2, 54, 26, 888671)]\n"
     ]
    }
   ],
   "source": [
    "print(netCDF4.num2date(tt,time_var.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids66 = np.where(np.logical_and(wh>0,qc==1))\n",
    "ids606 = \n",
    "whpos66 = wh[ids] and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days = [] #daystart\n",
    "daye = [] #dayend\n",
    "for k in range(len(wh)):\n",
    "    t1 = netCDF4.num2date(wh[k],time_var.units)\n",
    "    if k == 0: #get day 0. Then else: every day after that\n",
    "        days.append(0)\n",
    "        dd = netCDF4.num2date(wh[k],time_var.units)\n",
    "        it = 0\n",
    "    else:\n",
    "        if t1.day != dd.day: #if day 1 is not equal to day 2, then append\n",
    "            #print dd.day,t1.day\n",
    "            daye.append(k-1)\n",
    "            days.append(k)\n",
    "            it += 1\n",
    "            dd = netCDF4.num2date(wh[k],time_var.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130 whpos\n",
      "6130 qc_\n",
      "6130 lon_\n",
      "6130 tt_\n",
      "6130 lat_\n"
     ]
    }
   ],
   "source": [
    "whpos = wh[days]\n",
    "qc_ = qc[days]\n",
    "lon_ = lon[days]\n",
    "tt_ = tt[days]\n",
    "lat_ = lat[days]\n",
    "\n",
    "print len(whpos), 'whpos'\n",
    "print len(qc_),'qc_'\n",
    "print len(lon_),'lon_'\n",
    "print len(tt_),'tt_'\n",
    "print len(lat_),'lat_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new days\n",
      "mean whpos 1.7868134591673754\n",
      "max whpos 21.49700164794922\n",
      "min whpos 0.0\n",
      "min lon 145.00023\n",
      "min lon 145.00023\n",
      "max lon 145.99995\n",
      "min lat -13.99984\n",
      "max lat -13.000111\n",
      "1985-05-07 11:06:23.132808\n",
      "2019-02-15 23:59:15.640625\n"
     ]
    }
   ],
   "source": [
    "print 'new days'\n",
    "\n",
    "print 'mean whpos', np.mean(whpos)\n",
    "print 'max whpos',max(whpos)\n",
    "print 'min whpos', min (whpos)\n",
    "\n",
    "print 'min lon',min(lon_)\n",
    "print 'min lon',min(lon_)\n",
    "print 'max lon',max(lon_)\n",
    "\n",
    "print 'min lat', min(lat_)\n",
    "print 'max lat',max(lat_)\n",
    "\n",
    "print min(netCDF4.num2date(tt_,time_var.units))\n",
    "print max (netCDF4.num2date(tt_,time_var.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34802 whpos\n",
      "34802 qc_\n",
      "34802 lon_\n",
      "34802 tt_\n",
      "34802 lat_\n",
      "1.6800049060284783\n"
     ]
    }
   ],
   "source": [
    "ids = np.where(np.logical_and(wh>0,qc==1))\n",
    "\n",
    "\n",
    "whpos = wh[ids]\n",
    "qc_ = qc[ids]\n",
    "lon_ = lon[ids]\n",
    "tt_ = tt[ids]\n",
    "lat_ = lat[ids]\n",
    "\n",
    "print len(whpos), 'whpos'\n",
    "print len(qc_),'qc_'\n",
    "print len(lon_),'lon_'\n",
    "print len(tt_),'tt_'\n",
    "print len(lat_),'lat_'\n",
    "print np.mean(whpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'mean whpos', np.mean(whpos)\n",
    "print 'max whpos',max(whpos)\n",
    "print 'min whpos', min (whpos)\n",
    "\n",
    "print 'min lon',min(lon_)\n",
    "print 'min lon',min(lon_)\n",
    "print 'max lon',max(lon_)\n",
    "\n",
    "print 'min lat', min(lat_)\n",
    "print 'max lat',max(lat_)\n",
    "\n",
    "print min(netCDF4.num2date(tt_,time_var.units))\n",
    "print max (netCDF4.num2date(tt_,time_var.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(whpos)\n",
    "print min(netCDF4.num2date(tt_,time_var.units))\n",
    "print max(netCDF4.num2date(tt_,time_var.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(whpos)):\n",
    "    print netCDF4.num2date(tt_[k],time_var.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print days[0],daye[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(days)-1): \n",
    "    print np.mean(lon_[days[t]:days[t+1]]) #check if this is right? Length btn dates.\n",
    "    print len(lon_[days[t]:days[t+1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/numpy/ma/core.py:5159: RuntimeWarning: Mean of empty slice.\n",
      "  dtype=dtype, **kwargs)[()]\n",
      "/Users/bgh2-ra/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    }
   ],
   "source": [
    "#Practice\n",
    "\n",
    "meanwh = [] #mean wave height from each satellite track\n",
    "\n",
    "for t in range(len(days)-1):\n",
    "    meanwh.append(np.mean(whpos[days[t]:days[t+1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(meanwh)):\n",
    "    if k==0:\n",
    "        mwh = meanwh[k]\n",
    "    else:\n",
    "        mwh = np.append(mwh,meanwh[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwh[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mwh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(days[1],days[2]):\n",
    "    \n",
    "    print netCDF4.num2date(mwh[k],time_var.units),whpos[k]\n",
    "    \n",
    "print days[1],daye[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dont think I need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(days[1],days[2]):\n",
    "    \n",
    "    print netCDF4.num2date(tt_[k],time_var.units),whpos[k]\n",
    "    \n",
    "print days[1],daye[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(days[2],days[3]):\n",
    "    \n",
    "    print netCDF4.num2date(tt_[k],time_var.units),whpos[k]\n",
    "    \n",
    "print days[2],daye[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted1 = np.sort(tt_)\n",
    "for k in range(len(sorted1)):\n",
    "    print netCDF4.num2date(sorted1[k],time_var.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##EXTRACT DATA BY MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find time of large wave heights\n",
    "months = []\n",
    "for k in range(len(tt_)):\n",
    "    if whpos[k]>4.5:\n",
    "        dt = netCDF4.num2date(tt_[k],time_var.units)\n",
    "        months.append(dt.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print len(months)\n",
    "print months\n",
    "months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE THIS FOR MONTHS :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all january wave heights. USE tt_, as it will then call all other variables\n",
    "janWh = []\n",
    "febWh = []\n",
    "marWh = []\n",
    "aprWh = []\n",
    "mayWh = []\n",
    "junWh = []\n",
    "julWh = []\n",
    "augWh = []\n",
    "sepWh = []\n",
    "octWh = []\n",
    "novWh = []\n",
    "decWh = []\n",
    "\n",
    "for k in range(len(tt_)):\n",
    "    dt = netCDF4.num2date(tt_[k],time_var.units)\n",
    "    if dt.month == 1:\n",
    "        janWh.append(k)\n",
    "    if dt.month == 2:\n",
    "        febWh.append(k)\n",
    "    if dt.month == 3:\n",
    "        marWh.append(k)\n",
    "    if dt.month == 4:\n",
    "        aprWh.append(k)\n",
    "    if dt.month == 5:\n",
    "        mayWh.append(k)\n",
    "    if dt.month == 6:\n",
    "        junWh.append(k)\n",
    "    if dt.month == 7:\n",
    "        julWh.append(k)\n",
    "    if dt.month == 8:\n",
    "        augWh.append(k)\n",
    "    if dt.month == 9:\n",
    "        sepWh.append(k)\n",
    "    if dt.month == 10:\n",
    "        octWh.append(k)\n",
    "    if dt.month == 11:\n",
    "        novWh.append(k)\n",
    "    if dt.month == 12:\n",
    "        decWh.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "janW = whpos[janWh]\n",
    "febW = whpos[febWh]\n",
    "marW = whpos[marWh]\n",
    "aprW = whpos[aprWh]\n",
    "mayW = whpos[mayWh]\n",
    "junW = whpos[junWh]\n",
    "julW = whpos[julWh]\n",
    "augW = whpos[augWh]\n",
    "sepW = whpos[sepWh]\n",
    "octW = whpos[octWh]\n",
    "novW = whpos[novWh]\n",
    "decW = whpos[decWh]\n",
    "\n",
    "\n",
    "print 'Month       Min               Max                 Mean'\n",
    "print 'Jan', janW.min(),janW.max(),janW.mean()\n",
    "print 'Feb', febW.min(),febW.max(),febW.mean()\n",
    "print 'Mar', marW.min(),marW.max(),marW.mean()\n",
    "print 'Apr', aprW.min(),aprW.max(),aprW.mean()\n",
    "print 'May', mayW.min(),mayW.max(),mayW.mean()\n",
    "print 'Jun', junW.min(),junW.max(),junW.mean()\n",
    "print 'Jul', julW.min(),julW.max(),julW.mean()\n",
    "print 'Aug', augW.min(),augW.max(),augW.mean()\n",
    "print 'Sep', sepW.min(),sepW.max(),sepW.mean()\n",
    "print 'Oct', octW.min(),octW.max(),octW.mean()\n",
    "print 'Nov', novW.min(),novW.max(),novW.mean()\n",
    "print 'Dec', decW.min(),decW.max(),decW.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "janW = np.asarray(janWh)\n",
    "janW.min(),janW.max(),janW.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julyW = np.asarray(julyWh)\n",
    "julyW.min(),julyW.max(),julyW.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julyW"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
